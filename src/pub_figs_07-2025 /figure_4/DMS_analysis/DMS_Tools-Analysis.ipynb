{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da800c4d",
   "metadata": {},
   "source": [
    "## Exploring Blooms Labs DMS Tools package\n",
    "\n",
    "Using Bloom Lab DMS Tool's findSigSel function (https://jbloomlab.github.io/dms_tools2/dms_tools2.plot.html#dms_tools2.plot.findSigSel) on Abby Clyde's DMS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ddcda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import math\n",
    "import numbers\n",
    "import random\n",
    "import collections\n",
    "\n",
    "# import natsort\n",
    "import pandas\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import scipy.optimize\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "COLOR_BLIND_PALETTE = [\"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\",\n",
    "                       \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec23f04",
   "metadata": {},
   "source": [
    "## Function: findSigSel\n",
    "\n",
    "Following example vignette from https://jbloomlab.github.io/dms_tools2/dms_tools2.plot.html#dms_tools2.plot.findSigSel\n",
    "\n",
    "Manually adding source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb636d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSigSel(df, valcol, plotfile, fdr=0.05, title=None,\n",
    "               method='robust_hist', mle_frac_censor=0.005,\n",
    "               returnplot=False):\n",
    "    \"\"\"Finds \"significant\" selection at sites / mutations.\n",
    "\n",
    "    Designed for the case where most sites / mutations are not\n",
    "    under selection, but a few may be. It tries to find those\n",
    "    few that are under selection. \n",
    "\n",
    "    It does not use a mechanistic statistical model, but rather fits\n",
    "    a gamma distribution. The rationale for\n",
    "    a gamma distribution is that it is negative binomial's continuous\n",
    "    `analog <http://www.nehalemlabs.net/prototype/blog/2013/12/01/gamma-distribution-approximation-to-the-negative-binomial-distribution/>`_.\n",
    "    It then identifies sites that clearly have **larger** values than\n",
    "    expected under this distribution. It currently does not\n",
    "    identify sites with **smaller** (or more negative) than expected\n",
    "    values.\n",
    "\n",
    "    Args:\n",
    "        `df` (pandas DataFrame)\n",
    "            Contains data to analyze\n",
    "        `valcol` (string)\n",
    "            Column in `df` with values (e.g., `fracsurvive`)\n",
    "        `plotfile` (string)\n",
    "            Name of file to which we plot fit.\n",
    "        `fdr` (float)\n",
    "            Find sites that are significant at this `fdr`\n",
    "            given fitted distribution.\n",
    "        `title` (string or `None`)\n",
    "            Title for plot.\n",
    "        `method` (str)\n",
    "            Specifies how to fit gamma distribution, can have following values:\n",
    "\n",
    "              - 'robust_hist': bin the data, then use \n",
    "                `robust regression <http://scipy-cookbook.readthedocs.io/items/robust_regression.html>`_\n",
    "                (soft L1 loss) to fit a gamma distribution to the histogram.\n",
    "\n",
    "              - 'mle': fit the gamma distribution to the points by maximum\n",
    "                likelihood; see also `mle_frac_censor`.\n",
    "\n",
    "        `mle_frac_censor` (float)\n",
    "            Only meaningful if `method` is 'mle'. In this case, before fitting,\n",
    "            censor the data by setting the top `mle_frac_censor` largest values\n",
    "            to the `mle_frac_censor` largest value. This shrinks very large\n",
    "            outliers that affect fit.\n",
    "        `returnplot` (bool)\n",
    "            Return the matplotlib figure.\n",
    "\n",
    "    Returns:\n",
    "        Creates the plot in `plotfile`. Also returns\n",
    "        the 3-tuple `(df_sigsel, cutoff, gamma_fit)` where:\n",
    "\n",
    "            - `df_sigsel` is copy of `df` with new columns\n",
    "              `P`, `Q`, and `sig`. These give P value, Q\n",
    "              value, and whether site meets `fdr` cutoff\n",
    "              for significance.\n",
    "\n",
    "            - `cutoff` is the maximum value that is **not**\n",
    "              called significant. Because FDR is a property\n",
    "              of a distribution, this value cannot be \n",
    "              interpreted as meaning a new data point would\n",
    "              be called based on this cutoff, as the cutoff\n",
    "              would change. But `cutoff` is useful for \n",
    "              plotting to see significant / non-significant.\n",
    "\n",
    "            - `gamma_params` is a `numpy.ndarray` that of \n",
    "              length 3 that gives the shape, scale, and location\n",
    "              parameter of the fit gamma distribution.\n",
    "\n",
    "        If `returnplot` is `True`, then return\n",
    "        `((df_sigsel, cutoff, gamma_fit), fig)` where `fig`\n",
    "        is the matplotlib figure.\n",
    "\n",
    "    An example: First, simulate points from a gamma distribution:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> import pandas\n",
    "        >>> import scipy\n",
    "        >>> from dms_tools2.plot import findSigSel\n",
    "        >>>\n",
    "        >>> shape_sim = 1.5\n",
    "        >>> scale_sim = 0.005\n",
    "        >>> loc_sim = 0.0\n",
    "        >>> gamma_sim = scipy.stats.gamma(shape_sim, scale=scale_sim,\n",
    "        ...         loc=loc_sim)\n",
    "        >>> nsites = 1000\n",
    "        >>> scipy.random.seed(0)\n",
    "        >>> df = pandas.DataFrame.from_dict({\n",
    "        ...         'site':[r for r in range(nsites)],\n",
    "        ...         'fracsurvive':gamma_sim.rvs(nsites)})\n",
    "\n",
    "    Now make two sites have \"significantly\" higher values:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> sigsites = [100, 200]\n",
    "        >>> df.loc[sigsites, 'fracsurvive'] = 0.08\n",
    "\n",
    "    Now find the significant sites:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> plotfile = '_findSigSel.png'\n",
    "        >>> (df_sigsel, cutoff, gamma_params) = findSigSel(\n",
    "        ...         df, 'fracsurvive', plotfile, title='example')\n",
    "\n",
    "    Make sure the fitted params are close to the ones used to\n",
    "    simulate the data:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> numpy.allclose(shape_sim, gamma_params[0], rtol=0.1, atol=1e-3)\n",
    "        True\n",
    "        >>> numpy.allclose(scale_sim, gamma_params[1], rtol=0.1, atol=1e-3)\n",
    "        True\n",
    "        >>> numpy.allclose(loc_sim, gamma_params[2], rtol=0.1, atol=1e-3)\n",
    "        True\n",
    "\n",
    "    Check that we find the correct significant sites:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> set(sigsites) == set(df_sigsel.query('sig').site)\n",
    "        True\n",
    "\n",
    "    Make sure that sites above cutoff are significant:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> df_sigsel.query('sig').equals(df_sigsel.query('fracsurvive > @cutoff'))\n",
    "        True\n",
    "\n",
    "    Now repeat, getting and showing the plot:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> _, fig = findSigSel(\n",
    "        ...         df, 'fracsurvive', plotfile, title='example', returnplot=True)\n",
    "\n",
    "    Now use the 'mle' `method`:\n",
    "\n",
    "    .. nbplot::\n",
    "\n",
    "        >>> (df_sigsel_mle, _, _), fig_mle = findSigSel(\n",
    "        ...         df, 'fracsurvive', plotfile, title='example',\n",
    "        ...         method='mle', returnplot=True)\n",
    "        >>> set(df_sigsel_mle.query('sig').site) == set(sigsites)\n",
    "        True\n",
    "\n",
    "    \"\"\"\n",
    "    assert valcol in df.columns, \"no `valcol` {0}\".format(valcol)\n",
    "\n",
    "    newcols = {'P', 'Q', 'sig'}\n",
    "    assert not (newcols & set(df.columns)), \\\n",
    "            \"`df` already has {0}\".format(newcols)\n",
    "\n",
    "    # We fit curves to histogram. First we need to get bins.\n",
    "    try:\n",
    "        # try with Freedman Diaconis Estimator\n",
    "        binedges = numpy.histogram(df[valcol], bins='fd')[1]\n",
    "    except ValueError:\n",
    "        # fd will fail of lots of identical points\n",
    "        binedges = numpy.histogram(df[valcol], bins='doane')[1]\n",
    "\n",
    "    # get bin centers\n",
    "    bins = (binedges[ : -1] + binedges[1 : ]) / 2\n",
    "\n",
    "    # plot the histogram\n",
    "    plt.figure(figsize=(5.5, 4))\n",
    "    (heights, binedges, patches) = plt.hist(df[valcol],\n",
    "            bins=binedges, density=True, histtype='stepfilled',\n",
    "            color=COLOR_BLIND_PALETTE[2])\n",
    "\n",
    "    # initial guess gives correct mean and variance for\n",
    "    # gamma distribution with loc of 0\n",
    "    scale = df[valcol].var() / df[valcol].mean()\n",
    "    shape = df[valcol].mean() / scale\n",
    "    x0 = numpy.array([shape, scale, 0.0])\n",
    "\n",
    "    if method == 'robust_hist':\n",
    "        def _f(x, bins, heights):\n",
    "            \"\"\"Gamma distribution least squares fitting function.\n",
    "\n",
    "            Zero when distribution perfectly fits histogram.\n",
    "            `x` is `(shape, scale, loc)`.\n",
    "            \"\"\"\n",
    "            return (scipy.stats.gamma.pdf(bins, x[0], scale=x[1],\n",
    "                    loc=x[2]) - heights)\n",
    "\n",
    "        # fit using soft L1 loss for robust regression\n",
    "        # http://scipy-cookbook.readthedocs.io/items/robust_regression.html\n",
    "        fit = scipy.optimize.least_squares(_f, x0, args=(bins, heights),\n",
    "                                           loss='soft_l1')\n",
    "        gamma_params = fit.x\n",
    "        gamma_fit = scipy.stats.gamma(fit.x[0], scale=fit.x[1],\n",
    "                                      loc=fit.x[2])\n",
    "\n",
    "    elif method == 'mle':\n",
    "        vals = numpy.sort(df[valcol].values)\n",
    "        mle_n_censor = round(len(vals) * mle_frac_censor)\n",
    "        maxval = vals[-1 - mle_n_censor]\n",
    "        vals[vals > maxval] = maxval\n",
    "        fit_shape, fit_loc, fit_scale = scipy.stats.gamma.fit(vals,\n",
    "                                                              shape,\n",
    "                                                              scale=scale,\n",
    "                                                              loc=0)\n",
    "        gamma_params = numpy.array([fit_shape, fit_scale, fit_loc])\n",
    "        gamma_fit = scipy.stats.gamma(fit_shape, scale=fit_scale, loc=fit_loc)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"invalid `method` {method}\")\n",
    "\n",
    "    # add fit gamma distribution to plot\n",
    "    nfitbins = 500\n",
    "    if nfitbins > len(bins):\n",
    "        fitbins = numpy.linspace(bins[0], bins[-1], nfitbins)\n",
    "    else:\n",
    "        fitbins = bins\n",
    "    plt.plot(fitbins, gamma_fit.pdf(fitbins),\n",
    "            color=COLOR_BLIND_PALETTE[1])\n",
    "\n",
    "    # compute P and Q values\n",
    "    df_sigsel = (df.assign(P=lambda x: gamma_fit.sf(x[valcol]))\n",
    "                   .assign(Q=lambda x: multipletests(x.P, fdr, 'fdr_bh')[1])\n",
    "                   .assign(sig=lambda x: multipletests(x.P, fdr, 'fdr_bh')[0])\n",
    "                   )\n",
    "\n",
    "    # compute cutoff \n",
    "    cutoff = df_sigsel.query('not sig')[valcol].max()\n",
    "\n",
    "    # plot cutoff\n",
    "    # find first bin boundary greater than cutoff\n",
    "    if (binedges > cutoff).any():\n",
    "        bincutoff = binedges[binedges > cutoff][0]\n",
    "    else:\n",
    "        bincutoff = binedges[-1]\n",
    "    # now annotate plot\n",
    "    plt.axvline(bincutoff, color=COLOR_BLIND_PALETTE[3], ls='--', lw=0.75)\n",
    "    text_y = 0.95 * plt.ylim()[1]\n",
    "    (xmin, xmax) = plt.xlim()\n",
    "    if (bincutoff - xmin) < 0.75 * (xmax - xmin):\n",
    "        text_x = bincutoff + 0.01 * (xmax - xmin)\n",
    "        ha = 'left'\n",
    "    else:\n",
    "        text_x = bincutoff - 0.01 * (xmax - xmin)\n",
    "        ha = 'right'\n",
    "    if len(df_sigsel.query('sig')):\n",
    "        text = '{0} values\\nsignificant\\n($>${1})'.format(\n",
    "                len(df_sigsel.query('sig')), latexSciNot([cutoff])[0])\n",
    "    else:\n",
    "        text = 'no values\\nsignificant'\n",
    "    plt.text(text_x, text_y, text,\n",
    "            horizontalalignment=ha, verticalalignment='top',\n",
    "            color=COLOR_BLIND_PALETTE[3], size='small')\n",
    "\n",
    "    # put labels on plot\n",
    "    plt.xlabel(valcol.replace('_', ' '))\n",
    "    plt.ylabel('density')\n",
    "    if title:\n",
    "        plt.title(title.replace('_', ' '))\n",
    "\n",
    "    # save plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plotfile)\n",
    "\n",
    "    if returnplot:\n",
    "        return ((df_sigsel, cutoff, gamma_params), plt.gcf())\n",
    "    else:\n",
    "        plt.close()\n",
    "        return (df_sigsel, cutoff, gamma_params)\n",
    "\n",
    "    \n",
    "def latexSciNot(xlist):\n",
    "    \"\"\"\n",
    "    Converts list of numbers to LaTex scientific notation.\n",
    "    \"\"\"\n",
    "    if isinstance(xlist, numbers.Number):\n",
    "        isnum = True\n",
    "        xlist = [xlist]\n",
    "    else:\n",
    "        isnum = False\n",
    "    formatlist = []\n",
    "    for x in xlist:\n",
    "        xf = \"{0:.2g}\".format(x)\n",
    "        if xf[ : 2] == '1e':\n",
    "            xf = \"$10^{{{0}}}$\".format(int(xf[2 : ]))\n",
    "        elif xf[ : 3] == '-1e':\n",
    "            xf = \"$-10^{{{0}}}$\".format(int(xf[3 : ]))\n",
    "        elif 'e' in xf:\n",
    "            (d, exp) = xf.split('e')\n",
    "            xf = '${0} \\\\times 10^{{{1}}}$'.format(d, int(exp))\n",
    "        else:\n",
    "            xf = '${0}$'.format(xf)\n",
    "        formatlist.append(xf)\n",
    "    if isnum:\n",
    "        assert len(formatlist) == 1\n",
    "        formatlist = formatlist[0]\n",
    "    return formatlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6151d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate gamme distributed data\n",
    "shape_sim = 1.5\n",
    "scale_sim = 0.005\n",
    "loc_sim = 0.0\n",
    "gamma_sim = scipy.stats.gamma(shape_sim, scale=scale_sim, loc=loc_sim)\n",
    "nsites = 1000 # 1000 sites\n",
    "#scipy.random.seed(0)\n",
    "df = pandas.DataFrame.from_dict({\n",
    "    'site':[r for r in range(nsites)],\n",
    "    'fracsurvive':gamma_sim.rvs(nsites)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two points to stand out\n",
    "sigsites = [100, 200] # significant sites\n",
    "df.loc[sigsites, 'fracsurvive'] = 0.08 # setting frac survival to 8% for site at 100 and  at 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6119334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an example file to ensure function works\n",
    "plotfile = '_findSigSel.png' # file to print plot to\n",
    "(df_sigsel, cutoff, gamma_params) = findSigSel(df, 'fracsurvive', plotfile, title='example')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de04811",
   "metadata": {},
   "source": [
    "- `df_sigsel` is copy of `df` with new columns\n",
    "  `P`, `Q`, and `sig`. These give P value, Q\n",
    "  value, and whether site meets `fdr` cutoff\n",
    "  for significance.\n",
    "\n",
    "- `cutoff` is the maximum value that is **not**\n",
    "  called significant. Because FDR is a property\n",
    "  of a distribution, this value cannot be \n",
    "  interpreted as meaning a new data point would\n",
    "  be called based on this cutoff, as the cutoff\n",
    "  would change. But `cutoff` is useful for \n",
    "  plotting to see significant / non-significant.\n",
    "\n",
    "- `gamma_params` is a `numpy.ndarray` that of \n",
    "  length 3 that gives the shape, scale, and location\n",
    "  parameter of the fit gamma distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ffcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing gamma params\n",
    "gamma_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2962fcb",
   "metadata": {},
   "source": [
    "## Using bNAb data files \n",
    "\n",
    "`data` files: BF520_10-1074_mut_effect, BF520_3BNC117_mut_effect, TRO11_10-1074_mut_effect, TRO11_3BNC117_mut_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3243d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'BF520_3BNC117' # change filename here\n",
    "path = 'data/' + file + '_mut_effect.csv'\n",
    "df = pandas.read_csv(path)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc8fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for times_seen > 3\n",
    "\n",
    "df = df[df['times_seen']>3]\n",
    "#df = df[df['escape_median'] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6f842",
   "metadata": {},
   "source": [
    "The positive versus negative values for escape are different: positive values represent escape while negative values represent higher neutralization. So, we can fit two separate gamma distributions; one for escape effects and one for sensitization effects. \n",
    "\n",
    "You would just take the absolute value of the mutations that cause sensitization and use those so that they are positive rather than negative for the gamma distribution fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf47051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating sensitization and neutralization effects\n",
    "\n",
    "# if using Escape Median instead of Mean\n",
    "\n",
    "# df_neu = df[df['escape_median'] > 0]\n",
    "# df_sen = df[df['escape_median'] < 0]\n",
    "\n",
    "# df_sen['escape_median'] = numpy.abs(df_sen['escape_median'])\n",
    "\n",
    "# using Escape Mean instead of Median\n",
    "df_neu = df[df['escape_mean'] > 0]\n",
    "df_sen = df[df['escape_mean'] < 0]\n",
    "\n",
    "df_sen['escape_mean'] = numpy.abs(df_sen['escape_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FOR MEDIAN\n",
    "# for i in ['neutralization', 'sensitization']:\n",
    "#     if i == 'neutralization':\n",
    "#         df = df_neu\n",
    "#         plt_name = file + '_Neutralization'\n",
    "#     else:\n",
    "#         df = df_sen\n",
    "#         plt_name = file + '_Sensitization'\n",
    "#     plotfile = f'{plt_name}_findSigSel.png' # file to print plot to\n",
    "#     (df_sigsel, cutoff, gamma_params) = findSigSel(df, 'escape_median', plotfile, title=plt_name)\n",
    "    \n",
    "#     df_sigsel[df_sigsel['sig'] != False].to_csv(f'{plt_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d44192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR MEAN\n",
    "for i in ['neutralization', 'sensitization']:\n",
    "    if i == 'neutralization':\n",
    "        df = df_neu\n",
    "        plt_name = file + '_Neutralization_Mean'\n",
    "    else:\n",
    "        df = df_sen\n",
    "        plt_name = file + '_Sensitization_Mean'\n",
    "    plotfile = f'{plt_name}_findSigSel.png' # path to print plot \n",
    "    (df_sigsel, cutoff, gamma_params) = findSigSel(df, 'escape_mean', plotfile, title=plt_name)\n",
    "    # save the output as a CSV\n",
    "    df_sigsel[df_sigsel['sig'] != False].to_csv(f'{plt_name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
